{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneuralprophet\u001b[39;00m \u001b[39mimport\u001b[39;00m NeuralProphet\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneuralprophet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m set_random_seed\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/neuralprophet/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# make core features and version number accessible\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_version\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pytorch_lightning/__init__.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m     _logger\u001b[39m.\u001b[39maddHandler(logging\u001b[39m.\u001b[39mStreamHandler())\n\u001b[1;32m     32\u001b[0m     _logger\u001b[39m.\u001b[39mpropagate \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning_fabric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseed\u001b[39;00m \u001b[39mimport\u001b[39;00m seed_everything  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[39m# noqa: E402\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/lightning_fabric/__init__.py:23\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# In PyTorch 2.0+, setting this variable will force `torch.cuda.is_available()` and `torch.cuda.device_count()`\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# to use an NVML-based implementation that doesn't poison forks.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# https://github.com/pytorch/pytorch/issues/83973\u001b[39;00m\n\u001b[1;32m     20\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mPYTORCH_NVML_BASED_CUDA_CHECK\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning_fabric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfabric\u001b[39;00m \u001b[39mimport\u001b[39;00m Fabric  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning_fabric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseed\u001b[39;00m \u001b[39mimport\u001b[39;00m seed_everything  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     26\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mFabric\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mseed_everything\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/lightning_fabric/fabric.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Callable, cast, Dict, Generator, List, Mapping, Optional, overload, Sequence, Tuple, Union\n\u001b[0;32m---> 21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning_utilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply_func\u001b[39;00m \u001b[39mimport\u001b[39;00m apply_to_collection\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/__init__.py:229\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    228\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from neuralprophet import NeuralProphet\n",
    "from neuralprophet.utils import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 16:31:32.467777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sqlite3 import connect\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "from scipy.signal import detrend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "sns.set()\n",
    "import pandasql as psql\n",
    "#machine learning and statistical methods\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "#dataframe index manipulations\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "#selected preprocessing and evaluation methods\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import tensorflow as tf\n",
    "import torch \n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formtemplatesclones=pd.read_csv(\"/home/batuhan-saylam/Desktop/JotformProject/formTemplatesClones.csv\",parse_dates=[\"date\"])\n",
    "formtemplatescategories=pd.read_csv(\"/home/batuhan-saylam/Desktop/JotformProject/formTemplatesCategories.csv\")\n",
    "formtemplates=pd.read_excel(\"/home/batuhan-saylam/Desktop/JotformProject/formTemplates_1_.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "formtemplatescategoriesPharmacy=formtemplatescategories[formtemplatescategories[\"metaKeywords\"]=='Tax Forms']\n",
    "\n",
    "formtemplatesclones=formtemplatesclones.rename({\"templateID\":\"_id\"},axis=1)\n",
    "formtemplates=formtemplates.drop_duplicates()\n",
    "formandclone=pd.merge(formtemplates,formtemplatesclones,on=\"_id\")\n",
    "formtemplates=formtemplates.rename({\"_id\":\"id\"},axis=1)\n",
    "formtemplates=formtemplates.rename({\"_featuredCategory\":\"_id\"},axis=1)\n",
    "formtemplates2=pd.merge(formtemplatescategoriesPharmacy,formtemplates,on=\"_id\")\n",
    "formtemplates2=formtemplates2.rename({\"_id\":\"_featuredCategory\"},axis=1)\n",
    "formtemplates=formtemplates.rename({\"_id\":\"_featuredCategory\"},axis=1)\n",
    "df_melt = formtemplates.assign(_categories=formtemplates._categories.str.split(\",\"))\n",
    "formtemplates=df_melt._categories.apply(pd.Series) \\\n",
    "    .merge(formtemplates, right_index=True, left_index=True) \\\n",
    "    .drop([\"_categories\"], axis=1) \\\n",
    "    .melt(id_vars=['id',\"_title\",\"_slug\",\"_description\",\"_featuredCategory\",\"_language\"], value_name=\"_categories\") \\\n",
    "    .drop(\"variable\", axis=1) \n",
    "formtemplates=formtemplates.rename({\"_categories\":\"_id\"},axis=1)\n",
    "formtemplates3=pd.merge(formtemplatescategoriesPharmacy,formtemplates,on=\"_id\")\n",
    "formtemplates3=formtemplates3.rename({\"_id\":\"_categories\"},axis=1)\n",
    "formtemplates=formtemplates.rename({\"_id\":\"_categories\"},axis=1)\n",
    "formtemplates=formtemplates.rename({\"id\":\"_id\"},axis=1)\n",
    "formcat=pd.concat([formtemplates2,formtemplates3])\n",
    "formcat=formcat.rename({\"id\":\"_id\"},axis=1)\n",
    "formcat=formcat.loc[:,[\n",
    " 'name',\n",
    " 'description',\n",
    " 'metaKeywords',\n",
    " '_categories',\n",
    " '_id']]\n",
    "formandclone=formandclone.loc[:,[\n",
    "'_id',\n",
    " '_title',\n",
    " '_slug',\n",
    " '_description',\n",
    " '_language',\n",
    " '_featuredCategory',\n",
    " 'formID',\n",
    " 'form_type',\n",
    " 'source',\n",
    " 'date']]\n",
    "formclonecategnonnanPharmacy=pd.merge(formandclone,formcat,on=\"_id\")\n",
    "formclonecategnonnanPharmacy=formclonecategnonnanPharmacy.drop_duplicates(keep='first')\n",
    "\n",
    "formclonecategnonnanPharmacy.index=formclonecategnonnanPharmacy.date\n",
    "formclonecategnonnanPharmacy.index=formclonecategnonnanPharmacy.index.to_period(\"D\")\n",
    "formclonecategnonnanPharmacy=formclonecategnonnanPharmacy.rename({\"date\":\"date2\"},axis=1)\n",
    "formclonecategnonnanPharmacy[\"day\"]=formclonecategnonnanPharmacy.index.dayofweek\n",
    "formclonecategnonnanPharmacy[\"week\"]=formclonecategnonnanPharmacy.index.week\n",
    "formclonecategnonnanPharmacy[\"dayofyear\"]=formclonecategnonnanPharmacy.index.dayofyear\n",
    "formclonecategnonnanPharmacy[\"year\"]=formclonecategnonnanPharmacy.index.year\n",
    "formclonecategnonnanPharmacy[\"quarter\"]=formclonecategnonnanPharmacy.index.quarter\n",
    "formclonecategnonnanPharmacy[\"month\"]=formclonecategnonnanPharmacy.index.month\n",
    "formclonecategnonnanPharmacy.index=formclonecategnonnanPharmacy.index.to_timestamp()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerators\u001b[39;00m \u001b[39mimport\u001b[39;00m find_usable_cuda_devices\n\u001b[1;32m      3\u001b[0m \u001b[39m# Find two GPUs on the system that are not already occupied\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m, devices\u001b[39m=\u001b[39mfind_usable_cuda_devices(\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "\n",
    "# Find two GPUs on the system that are not already occupied\n",
    "trainer = Trainer(accelerator=\"cuda\", devices=find_usable_cuda_devices(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 8700\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "__CUDA Device Total Memory [GB]: 4.094164992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=psql.sqldf(\"select count(_id),date,year,dayofyear from formclonecategnonnanPharmacy  group by date\")\n",
    "\n",
    "df.index=df.date.tolist()\n",
    "df.index=pd.to_datetime(df.index)\n",
    "df.index=df.index.to_period(\"D\")\n",
    "df.index=df.index.to_timestamp()\n",
    "df.index=df.index.strftime('%d-%m-%Y')\n",
    "df[\"date\"]=pd.to_datetime(df[\"date\"])\n",
    "\n",
    "\n",
    "df=df.rename({\"count(_id)\":\"y\"},axis=1)\n",
    "df=df.rename({\"date\":\"ds\"},axis=1)\n",
    "df=df.loc[:,[\"y\",\"ds\"]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits = 5)\n",
    "days = np.sort(df.index.unique())\n",
    "for train_index, test_index in tss.split(df):\n",
    "    train_days, test_days = days[train_index], days[test_index]\n",
    "    X_train, X_test = df.loc[train_days,], df.loc[test_days,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "# Init ModelCheckpoint callback, monitoring 'val_loss'\n",
    "checkpoint_callback = EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "class _EarlyStopping(EarlyStopping, pl.Callback):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "early_stop_callback = _EarlyStopping(monitor=\"Loss\",  mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "checkpoint_callback2 = EarlyStopping(monitor=\"Loss\",mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency YS corresponds to 71.337% of the data.\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency YS\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb5e28735894352a7d369ebdbad0602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_random_seed(0)\n",
    "m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"check_val_every_n_epoch\":1,\"callbacks\":[checkpoint_callback]},daily_seasonality=False,epochs=1000)\n",
    "m.add_country_holidays(country_name='US')\n",
    "df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,learning_rate=,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/batuhan-saylam/Desktop/lightning_logs/version_2/checkpoints/epoch=516-step=15510.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 516,\n",
       " 'global_step': 15510,\n",
       " 'pytorch-lightning_version': '1.9.5',\n",
       " 'state_dict': OrderedDict([('trend.bias', tensor([-0.2320], device='cuda:0')),\n",
       "              ('trend.trend_k0', tensor([[[0.7220]]], device='cuda:0')),\n",
       "              ('trend.trend_deltas',\n",
       "               tensor([[[ 1.0398,  0.4710, -0.3245, -1.2271,  1.0922,  0.4679, -0.5985,\n",
       "                          0.1880,  1.5828,  1.7215, -0.7956]]], device='cuda:0')),\n",
       "              ('trend.trend_changepoints_t',\n",
       "               tensor([0.0000, 0.0727, 0.1455, 0.2182, 0.2909, 0.3636, 0.4364, 0.5091, 0.5818,\n",
       "                       0.6545, 0.7273], device='cuda:0')),\n",
       "              ('seasonality.season_params.weekly',\n",
       "               tensor([[[-0.0972,  0.0429,  0.0467,  0.0049, -0.0113, -0.0013]]],\n",
       "                      device='cuda:0')),\n",
       "              ('seasonality.season_params.yearly',\n",
       "               tensor([[[0.0737, 0.2516, 0.0950, 0.0817, 0.0566, 0.0636, 0.0497, 0.0262,\n",
       "                         0.0578, 0.0246, 0.0212, 0.0056]]], device='cuda:0')),\n",
       "              ('event_params.additive',\n",
       "               tensor([[-0.5058, -0.4256,  0.0418,  0.3344, -0.1855,  0.1530,  0.0872, -0.0973,\n",
       "                         0.0918,  0.4194,  1.4587, -0.0796, -0.2654, -0.2621, -0.1515, -0.0166]],\n",
       "                      device='cuda:0')),\n",
       "              ('event_params.multiplicative',\n",
       "               tensor([], device='cuda:0', size=(1, 0)))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 15510},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 15510,\n",
       "     'completed': 15510,\n",
       "     'started': 15510,\n",
       "     'processed': 15510},\n",
       "    'current': {'ready': 30, 'completed': 30, 'started': 30, 'processed': 30},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.batch_loop.state_dict': {},\n",
       "   'epoch_loop.batch_loop.optimizer_loop.state_dict': {},\n",
       "   'epoch_loop.batch_loop.optimizer_loop.optim_progress': {'optimizer': {'step': {'total': {'ready': 0,\n",
       "       'completed': 0},\n",
       "      'current': {'ready': 0, 'completed': 0}},\n",
       "     'zero_grad': {'total': {'ready': 0, 'completed': 0, 'started': 0},\n",
       "      'current': {'ready': 0, 'completed': 0, 'started': 0}}},\n",
       "    'optimizer_position': 0},\n",
       "   'epoch_loop.batch_loop.manual_loop.state_dict': {},\n",
       "   'epoch_loop.batch_loop.manual_loop.optim_step_progress': {'total': {'ready': 15510,\n",
       "     'completed': 15510},\n",
       "    'current': {'ready': 15510, 'completed': 15510}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.dataloader_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.epoch_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.epoch_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False},\n",
       "   'epoch_progress': {'total': {'ready': 517,\n",
       "     'completed': 516,\n",
       "     'started': 517,\n",
       "     'processed': 517},\n",
       "    'current': {'ready': 517,\n",
       "     'completed': 516,\n",
       "     'started': 517,\n",
       "     'processed': 517}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'dataloader_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.state_dict': {},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'dataloader_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.state_dict': {},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'dataloader_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.state_dict': {},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"EarlyStopping{'monitor': 'Loss', 'mode': 'min'}\": {'wait_count': 0,\n",
       "   'stopped_epoch': 0,\n",
       "   'best_score': tensor(0.0195, device='cuda:0'),\n",
       "   'patience': 20},\n",
       "  \"ModelCheckpoint{'monitor': 'Loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': 'Loss',\n",
       "   'best_model_score': tensor(0.0195, device='cuda:0'),\n",
       "   'best_model_path': '/home/batuhan-saylam/Desktop/lightning_logs/version_2/checkpoints/epoch=516-step=15510.ckpt',\n",
       "   'current_score': tensor(0.0195, device='cuda:0'),\n",
       "   'dirpath': '/home/batuhan-saylam/Desktop/lightning_logs/version_2/checkpoints',\n",
       "   'best_k_models': {'/home/batuhan-saylam/Desktop/lightning_logs/version_2/checkpoints/epoch=516-step=15510.ckpt': tensor(0.0195, device='cuda:0')},\n",
       "   'kth_best_model_path': '/home/batuhan-saylam/Desktop/lightning_logs/version_2/checkpoints/epoch=516-step=15510.ckpt',\n",
       "   'kth_value': tensor(0.0195, device='cuda:0'),\n",
       "   'last_model_path': '/home/batuhan-saylam/Desktop/lightning_logs/version_2/checkpoints/last.ckpt'}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(15510.),\n",
       "     'exp_avg': tensor([0.0072], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([0.0011], device='cuda:0')},\n",
       "    1: {'step': tensor(15510.),\n",
       "     'exp_avg': tensor([[[0.0051]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[0.0006]]], device='cuda:0')},\n",
       "    2: {'step': tensor(15510.),\n",
       "     'exp_avg': tensor([[[0.0002, 0.0002, 0.0004, 0.0005, 0.0001, 0.0004, 0.0007, 0.0007,\n",
       "               0.0004, 0.0003, 0.0012]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[5.7885e-06, 5.7032e-06, 5.5973e-06, 5.5864e-06, 5.1294e-06,\n",
       "               4.8261e-06, 4.7752e-06, 4.5574e-06, 4.2189e-06, 4.0912e-06,\n",
       "               1.5156e-05]]], device='cuda:0')},\n",
       "    3: {'step': tensor(15510.),\n",
       "     'exp_avg': tensor([[[-0.0053,  0.0006, -0.0019, -0.0052, -0.0029, -0.0097]]],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[0.0006, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005]]], device='cuda:0')},\n",
       "    4: {'step': tensor(15510.),\n",
       "     'exp_avg': tensor([[[ 0.0042,  0.0045,  0.0066,  0.0039, -0.0017,  0.0011,  0.0005,\n",
       "               -0.0029,  0.0011, -0.0006, -0.0040,  0.0030]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[0.0002, 0.0008, 0.0004, 0.0007, 0.0005, 0.0006, 0.0005, 0.0005,\n",
       "               0.0006, 0.0005, 0.0006, 0.0005]]], device='cuda:0')},\n",
       "    5: {'step': tensor(15510.),\n",
       "     'exp_avg': tensor([[ 7.4556e-06,  2.5480e-06, -8.3623e-05,  0.0000e+00, -2.2601e-04,\n",
       "               3.4287e-04, -1.3119e-05, -4.7087e-05, -1.0872e-04,  0.0000e+00,\n",
       "              -6.3655e-06, -3.9641e-05, -3.9699e-05,  0.0000e+00,  1.1871e-05,\n",
       "               9.0910e-04]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.3794e-09, 1.3787e-08, 5.6030e-08, 0.0000e+00, 3.4791e-06, 8.2097e-07,\n",
       "              3.4752e-07, 1.1800e-07, 2.4956e-05, 0.0000e+00, 1.5226e-07, 8.4506e-06,\n",
       "              5.4760e-07, 0.0000e+00, 5.1549e-07, 4.1973e-06]], device='cuda:0')}},\n",
       "   'param_groups': [{'lr': 0.0007809802583395039,\n",
       "     'betas': (0.8719020179700855, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0.001,\n",
       "     'amsgrad': False,\n",
       "     'foreach': None,\n",
       "     'maximize': False,\n",
       "     'capturable': False,\n",
       "     'initial_lr': 1e-05,\n",
       "     'max_lr': 0.001,\n",
       "     'min_lr': 2e-09,\n",
       "     'max_momentum': 0.95,\n",
       "     'base_momentum': 0.85,\n",
       "     'params': [0, 1, 2, 3, 4, 5, 6]}]}],\n",
       " 'lr_schedulers': [{'total_steps': 30000,\n",
       "   '_schedule_phases': [{'end_step': 8999.0,\n",
       "     'start_lr': 'initial_lr',\n",
       "     'end_lr': 'max_lr',\n",
       "     'start_momentum': 'max_momentum',\n",
       "     'end_momentum': 'base_momentum'},\n",
       "    {'end_step': 29999,\n",
       "     'start_lr': 'max_lr',\n",
       "     'end_lr': 'min_lr',\n",
       "     'start_momentum': 'base_momentum',\n",
       "     'end_momentum': 'max_momentum'}],\n",
       "   'anneal_func': <bound method OneCycleLR._annealing_cos of <torch.optim.lr_scheduler.OneCycleLR object at 0x7f7d7f820580>>,\n",
       "   'cycle_momentum': True,\n",
       "   'use_beta1': True,\n",
       "   'base_lrs': [1e-05],\n",
       "   'last_epoch': 15510,\n",
       "   'verbose': False,\n",
       "   '_step_count': 15511,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.0007809802583395039]}],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'config_seasonality': ConfigSeasonality(mode='additive', computation='fourier', reg_lambda=0, yearly_arg='auto', weekly_arg='auto', daily_arg='auto', periods=OrderedDict([('yearly', Season(resolution=6, period=365.25, arg='auto', condition_name=None)), ('weekly', Season(resolution=3, period=7, arg='auto', condition_name=None))]), global_local='global', condition_name=None),\n",
       "  'config_train': Train(learning_rate=0.001, epochs=1000, batch_size=32, loss_func=SmoothL1Loss(), optimizer=<class 'torch.optim.adamw.AdamW'>, quantiles=[0.5], optimizer_args={'weight_decay': 0.001}, scheduler=<class 'torch.optim.lr_scheduler.OneCycleLR'>, scheduler_args={'pct_start': 0.3, 'anneal_strategy': 'cos', 'div_factor': 100.0, 'final_div_factor': 5000.0}, newer_samples_weight=2, newer_samples_start=0.0, reg_delay_pct=0.5, reg_lambda_trend=None, trend_reg_threshold=False, n_data=935, loss_func_name='SmoothL1Loss', lr_finder_args={}),\n",
       "  'config_trend': Trend(growth='linear', changepoints=array([0.        , 0.07272727, 0.14545455, 0.21818182, 0.29090909,\n",
       "         0.36363636, 0.43636364, 0.50909091, 0.58181818, 0.65454545,\n",
       "         0.72727273]), n_changepoints=10, changepoints_range=0.8, trend_reg=0, trend_reg_threshold=None, trend_global_local='global'),\n",
       "  'config_ar': AR(n_lags=0, ar_reg=None, ar_layers=[]),\n",
       "  'config_normalization': Normalization(normalize='auto', global_normalization=True, global_time_normalization=True, unknown_data_normalization=False, local_data_params=OrderedDict([('__df__', OrderedDict([('ds', ShiftScale(shift=Timestamp('2020-01-01 00:00:00'), scale=Timedelta('1295 days 00:00:00'))), ('y', ShiftScale(shift=1, scale=39.0))]))]), global_data_params=OrderedDict([('ds', ShiftScale(shift=Timestamp('2020-01-01 00:00:00'), scale=Timedelta('1295 days 00:00:00'))), ('y', ShiftScale(shift=1, scale=39.0))])),\n",
       "  'config_lagged_regressors': None,\n",
       "  'config_regressors': None,\n",
       "  'config_events': None,\n",
       "  'config_holidays': Holidays(country='US', lower_window=0, upper_window=0, mode='additive', reg_lambda=None, holiday_names={'Veterans Day (Observed)', 'Martin Luther King Jr. Day', \"New Year's Day (Observed)\", 'Christmas Day', 'Memorial Day', 'Juneteenth National Independence Day (Observed)', 'Christmas Day (Observed)', \"New Year's Day\", 'Thanksgiving', 'Labor Day', 'Columbus Day', 'Juneteenth National Independence Day', \"Washington's Birthday\", 'Independence Day (Observed)', 'Independence Day', 'Veterans Day'}),\n",
       "  'n_forecasts': 1,\n",
       "  'n_lags': 0,\n",
       "  'max_lags': 0,\n",
       "  'ar_layers': [],\n",
       "  'lagged_reg_layers': [],\n",
       "  'compute_components_flag': False,\n",
       "  'metrics': {'MAE': MeanAbsoluteError(), 'RMSE': MeanSquaredError()},\n",
       "  'id_list': ['__df__'],\n",
       "  'num_trends_modelled': 1,\n",
       "  'num_seasonalities_modelled': 1,\n",
       "  'meta_used_in_model': False}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
