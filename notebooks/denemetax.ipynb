{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 18:28:30.405912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sqlite3 import connect\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "from scipy.signal import detrend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "sns.set()\n",
    "import pandasql as psql\n",
    "#machine learning and statistical methods\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "#dataframe index manipulations\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "#selected preprocessing and evaluation methods\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import tensorflow as tf\n",
    "import torch \n",
    "import pickle\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "formtemplatesclones=pd.read_csv(\"/home/batuhan-saylam/Desktop/JotformProject/formTemplatesClones.csv\",parse_dates=[\"date\"])\n",
    "formtemplatescategories=pd.read_csv(\"/home/batuhan-saylam/Desktop/JotformProject/formTemplatesCategories.csv\")\n",
    "formtemplates=pd.read_excel(\"/home/batuhan-saylam/Desktop/JotformProject/formTemplates_1_.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "formtemplatescategoriesPharmacy=formtemplatescategories[formtemplatescategories[\"metaKeywords\"]=='Tax Forms']\n",
    "\n",
    "formtemplatesclones=formtemplatesclones.rename({\"templateID\":\"_id\"},axis=1)\n",
    "formtemplates=formtemplates.drop_duplicates()\n",
    "formandclone=pd.merge(formtemplates,formtemplatesclones,on=\"_id\")\n",
    "formtemplates=formtemplates.rename({\"_id\":\"id\"},axis=1)\n",
    "formtemplates=formtemplates.rename({\"_featuredCategory\":\"_id\"},axis=1)\n",
    "formtemplates2=pd.merge(formtemplatescategoriesPharmacy,formtemplates,on=\"_id\")\n",
    "formtemplates2=formtemplates2.rename({\"_id\":\"_featuredCategory\"},axis=1)\n",
    "formtemplates=formtemplates.rename({\"_id\":\"_featuredCategory\"},axis=1)\n",
    "df_melt = formtemplates.assign(_categories=formtemplates._categories.str.split(\",\"))\n",
    "formtemplates=df_melt._categories.apply(pd.Series) \\\n",
    "    .merge(formtemplates, right_index=True, left_index=True) \\\n",
    "    .drop([\"_categories\"], axis=1) \\\n",
    "    .melt(id_vars=['id',\"_title\",\"_slug\",\"_description\",\"_featuredCategory\",\"_language\"], value_name=\"_categories\") \\\n",
    "    .drop(\"variable\", axis=1) \n",
    "formtemplates=formtemplates.rename({\"_categories\":\"_id\"},axis=1)\n",
    "formtemplates3=pd.merge(formtemplatescategoriesPharmacy,formtemplates,on=\"_id\")\n",
    "formtemplates3=formtemplates3.rename({\"_id\":\"_categories\"},axis=1)\n",
    "formtemplates=formtemplates.rename({\"_id\":\"_categories\"},axis=1)\n",
    "formtemplates=formtemplates.rename({\"id\":\"_id\"},axis=1)\n",
    "formcat=pd.concat([formtemplates2,formtemplates3])\n",
    "formcat=formcat.rename({\"id\":\"_id\"},axis=1)\n",
    "formcat=formcat.loc[:,[\n",
    " 'name',\n",
    " 'description',\n",
    " 'metaKeywords',\n",
    " '_categories',\n",
    " '_id']]\n",
    "formandclone=formandclone.loc[:,[\n",
    "'_id',\n",
    " '_title',\n",
    " '_slug',\n",
    " '_description',\n",
    " '_language',\n",
    " '_featuredCategory',\n",
    " 'formID',\n",
    " 'form_type',\n",
    " 'source',\n",
    " 'date']]\n",
    "formclonecategnonnanPharmacy=pd.merge(formandclone,formcat,on=\"_id\")\n",
    "formclonecategnonnanPharmacy=formclonecategnonnanPharmacy.drop_duplicates(keep='first')\n",
    "\n",
    "formclonecategnonnanPharmacy.index=formclonecategnonnanPharmacy.date\n",
    "formclonecategnonnanPharmacy.index=formclonecategnonnanPharmacy.index.to_period(\"D\")\n",
    "formclonecategnonnanPharmacy=formclonecategnonnanPharmacy.rename({\"date\":\"date2\"},axis=1)\n",
    "formclonecategnonnanPharmacy[\"day\"]=formclonecategnonnanPharmacy.index.dayofweek\n",
    "formclonecategnonnanPharmacy[\"week\"]=formclonecategnonnanPharmacy.index.week\n",
    "formclonecategnonnanPharmacy[\"dayofyear\"]=formclonecategnonnanPharmacy.index.dayofyear\n",
    "formclonecategnonnanPharmacy[\"year\"]=formclonecategnonnanPharmacy.index.year\n",
    "formclonecategnonnanPharmacy[\"quarter\"]=formclonecategnonnanPharmacy.index.quarter\n",
    "formclonecategnonnanPharmacy[\"month\"]=formclonecategnonnanPharmacy.index.month\n",
    "formclonecategnonnanPharmacy.index=formclonecategnonnanPharmacy.index.to_timestamp()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=psql.sqldf(\"select count(_id),date,year,dayofyear from formclonecategnonnanPharmacy  group by date\")\n",
    "\n",
    "df.index=df.date.tolist()\n",
    "df.index=pd.to_datetime(df.index)\n",
    "df.index=df.index.to_period(\"D\")\n",
    "df.index=df.index.to_timestamp()\n",
    "df.index=df.index.strftime('%d-%m-%Y')\n",
    "df[\"date\"]=pd.to_datetime(df[\"date\"])\n",
    "\n",
    "\n",
    "df=df.rename({\"count(_id)\":\"y\"},axis=1)\n",
    "df=df.rename({\"date\":\"ds\"},axis=1)\n",
    "df=df.loc[:,[\"y\",\"ds\"]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "df2=df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits = 5)\n",
    "days = np.sort(df2.index.unique())\n",
    "for train_index, test_index in tss.split(df2):\n",
    "    train_days, test_days = days[train_index], days[test_index]\n",
    "    X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = pd.DataFrame(columns = ['Parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_neuralprophet = {\n",
    "    \"learning_rate\":[0.01,0.1,1],\n",
    "    'seasonality_mode':('multiplicative','additive'),\n",
    "    'batch_size':[8,16,32],\n",
    "    'weekly_seasonality':(True,False),\n",
    "    \"n_changepoints\":[5,10,15],\n",
    "    \"changepoints_range\":[0.1,0.5,0.8,1],\n",
    "    \"trend_reg\":[0,0.1,0.5,1],\n",
    "    \"trend_reg_threshold\":(True,False),\n",
    "    }\n",
    "grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'seasonality_mode': 'multiplicative', 'batch_size': 8, 'weekly_seasonality': True, 'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.1, 'trend_reg': 0, 'trend_reg_threshold': True, 'seasonality_reg': 0}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'petience'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(p)\n\u001b[1;32m      3\u001b[0m set_random_seed(\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m m \u001b[39m=\u001b[39m NeuralProphet(trainer_config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39maccelerator\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m:[EarlyStopping(monitor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mLoss_val\u001b[39;49m\u001b[39m\"\u001b[39;49m,mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m\"\u001b[39;49m,petience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)]},accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m,daily_seasonality\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,epochs\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mp)\n\u001b[1;32m      5\u001b[0m m\u001b[39m.\u001b[39madd_country_holidays(country_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUS\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m m\u001b[39m.\u001b[39mfit(X_train, freq\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m,early_stopping\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,progress\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplot\u001b[39m\u001b[39m\"\u001b[39m,validation_df\u001b[39m=\u001b[39mX_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'petience'"
     ]
    }
   ],
   "source": [
    "for p in grid_neuralprophet:\n",
    "    print(p)\n",
    "    set_random_seed(0)\n",
    "    m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "    m.add_country_holidays(country_name='US')\n",
    "    m.fit(X_train, freq=\"D\",early_stopping=True,progress=\"plot\",validation_df=X_test)\n",
    "    forecast = m.predict(X_test)\n",
    "    model_parameters =model_parameters.append({'Parameters':p},ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
