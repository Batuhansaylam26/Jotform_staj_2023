{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd \n",
    "from sqlite3 import connect\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "from scipy.signal import detrend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "sns.set()\n",
    "import pandasql as psql\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_trainer:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def train(self):\n",
    "        smoothing=[\"no\",\"rolling\",\"rolling-gaussian\",\"resample\",\"exponential\",\"exponential2\",\"exponential3\"]\n",
    "        method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        df=self.data.copy()\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "            'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "            'holidays_prior_scale':[0.01,0.1,1,10],\n",
    "            'seasonality_mode':['additive', 'multiplicative']\n",
    "            }\n",
    "        grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"epochs\":[100,200,500,1000],\n",
    "            \"batch_size\":[8,16,32,64,128],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            \"weekly_seasonality\":(True,False),\n",
    "            \"daily_seasonality\":(True,False)}\n",
    "        grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "        for i in smoothing:\n",
    "            df2=df.copy()\n",
    "            df2.index=df2[\"ds\"]\n",
    "            df2.index=pd.to_datetime(df2.index)\n",
    "            for j in method:\n",
    "                if i ==\"no\":\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        season=season.fillna(0)\n",
    "                        mape1=mean_absolute_percentage_error(df[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            model = Prophet(**p)\n",
    "                            model=model.fit(df)\n",
    "                            forecast = model.predict(df)\n",
    "                            mape1=mean_absolute_percentage_error(df[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df, freq=\"D\")\n",
    "                            forecast = m.predict(df)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"rolling\":\n",
    "                    df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "                    df2=df2.dropna()\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            model = Prophet(**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"rolling-gaussian\":\n",
    "                    df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "                    df2=df2.dropna()\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            model = Prophet(**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"resample\":\n",
    "                    df2=df2.resample(\"W\").mean()\n",
    "                    df2=df2.dropna()\n",
    "                    df2[\"ds\"]=df2.index.tolist()\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            model = Prophet(**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)  \n",
    "                if i==\"exponential\":\n",
    "                    es_simple = SimpleExpSmoothing(df2[\"y\"]).fit()\n",
    "                    df2[\"y\"]=es_simple.fittedvalues\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season=season.fillna(0)\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            model = Prophet(**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"exponential2\":\n",
    "                    es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= None, seasonal_periods= None).fit()\n",
    "                    df2[\"y\"]=es_simple.fittedvalues\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            model = Prophet(**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True) \n",
    "                if i==\"exponential3\":\n",
    "                    es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "                    df2[\"y\"]=es_simple.fittedvalues\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            model = Prophet(**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "\n",
    "        minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"mape\"].argmin()])\n",
    "        self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"             if i ==\"no\":\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        season=season.fillna(0)\n",
    "                        mape1=mean_absolute_percentage_error(df[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(df)\n",
    "                            forecast = model.predict(df)\n",
    "                            mape1=mean_absolute_percentage_error(df[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df, freq=\"D\")\n",
    "                            forecast = m.predict(df)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd \n",
    "from sqlite3 import connect\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "from scipy.signal import detrend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "sns.set()\n",
    "import pandasql as psql\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def train(self):\n",
    "        smoothing=[\"rolling\",\"rolling-gaussian\",\"resample\",\"exponential3\"]\n",
    "        method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        df=self.data.copy()\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"epochs\":[100,500,1000],\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "        for i in smoothing:\n",
    "            df2=df.copy()\n",
    "            df2.index=df2[\"ds\"]\n",
    "            df2.index=pd.to_datetime(df2.index)\n",
    "            for j in method:\n",
    "                if i==\"rolling\":\n",
    "                    df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "                    df2=df2.dropna()\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"rolling-gaussian\":\n",
    "                    df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "                    df2=df2.dropna()\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"resample\":\n",
    "                    df2=df2.resample(\"W\").mean()\n",
    "                    df2=df2.dropna()\n",
    "                    df2[\"ds\"]=df2.index.tolist()\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)  \n",
    "                if i==\"exponential3\":\n",
    "                    es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "                    df2[\"y\"]=es_simple.fittedvalues\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "\n",
    "        minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"mape\"].argmin()])\n",
    "        self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd \n",
    "from sqlite3 import connect\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "from scipy.signal import detrend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "sns.set()\n",
    "import pandasql as psql\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def train(self):\n",
    "        smoothing=[\"rolling\",\"rolling-gaussian\",\"resample\",\"exponential3\"]\n",
    "        method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        df=self.data.copy()\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        for i in smoothing:\n",
    "            df2=df.copy()\n",
    "            df2.index=df2[\"ds\"]\n",
    "            df2.index=pd.to_datetime(df2.index)\n",
    "            for j in method:\n",
    "                params_grid_neuralprophet = {\n",
    "                    \"learning_rate\":[0.01,0.1,1],\n",
    "                    'seasonality_mode':('multiplicative','additive'),\n",
    "                    'batch_size':[8,16,32],\n",
    "                    'weekly_seasonality':(True,False)}\n",
    "                grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "                if i==\"rolling\":\n",
    "                    df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "                    df2=df2.dropna()\n",
    "                    tss = TimeSeriesSplit(n_splits = 5)\n",
    "                    days = np.sort(df2.index.unique())\n",
    "                    for train_index, test_index in tss.split(df2):\n",
    "                        train_days, test_days = days[train_index], days[test_index]\n",
    "                        X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            p[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"rolling-gaussian\":\n",
    "                    df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "                    df2=df2.dropna()\n",
    "                    tss = TimeSeriesSplit(n_splits = 5)\n",
    "                    days = np.sort(df2.index.unique())\n",
    "                    for train_index, test_index in tss.split(df2):\n",
    "                        train_days, test_days = days[train_index], days[test_index]\n",
    "                        X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"resample\":\n",
    "                    df2=df2.resample(\"W\").mean()\n",
    "                    df2=df2.dropna()\n",
    "                    df2[\"ds\"]=df2.index.tolist()\n",
    "                    tss = TimeSeriesSplit(n_splits = 5)\n",
    "                    days = np.sort(df2.index.unique())\n",
    "                    for train_index, test_index in tss.split(df2):\n",
    "                        train_days, test_days = days[train_index], days[test_index]\n",
    "                        X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)  \n",
    "                if i==\"exponential3\":\n",
    "                    es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "                    df2[\"y\"]=es_simple.fittedvalues\n",
    "                    tss = TimeSeriesSplit(n_splits = 5)\n",
    "                    days = np.sort(df2.index.unique())\n",
    "                    for train_index, test_index in tss.split(df2):\n",
    "                        train_days, test_days = days[train_index], days[test_index]\n",
    "                        X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index,format=\"%d-%m-%Y\")\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(df2)\n",
    "                            forecast = model.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(df2[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            m.fit(df2, freq=\"D\")\n",
    "                            forecast = m.predict(df2)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "\n",
    "        minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"mape\"].argmin()])\n",
    "        self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd \n",
    "from sqlite3 import connect\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "from scipy.signal import detrend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "sns.set()\n",
    "import pandasql as psql\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def train(self):\n",
    "        smoothing=[\"rolling\",\"rolling-gaussian\",\"resample\",\"exponential3\"]\n",
    "        method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        df=self.data.copy()\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        for i in smoothing:\n",
    "            df2=df.copy()\n",
    "            df2.index=df2[\"ds\"]\n",
    "            df2.index=pd.to_datetime(df2.index)\n",
    "            for j in method:\n",
    "                params_grid_neuralprophet = {\n",
    "                    \"learning_rate\":[0.01,0.1,1],\n",
    "                    'seasonality_mode':('multiplicative','additive'),\n",
    "                    'batch_size':[8,16,32],\n",
    "                    'weekly_seasonality':(True,False)}\n",
    "                grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "                if i==\"rolling\":\n",
    "                    df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "                    df2=df2.dropna()\n",
    "                    tss = TimeSeriesSplit(n_splits = 5)\n",
    "                    days = np.sort(df2.index.unique())\n",
    "                    for train_index, test_index in tss.split(df2):\n",
    "                        train_days, test_days = days[train_index], days[test_index]\n",
    "                        X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            p[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"rolling-gaussian\":\n",
    "                    df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "                    df2=df2.dropna()\n",
    "                    tss = TimeSeriesSplit(n_splits = 5)\n",
    "                    days = np.sort(df2.index.unique())\n",
    "                    for train_index, test_index in tss.split(df2):\n",
    "                        train_days, test_days = days[train_index], days[test_index]\n",
    "                        X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            p[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"resample\":\n",
    "                    df2=df2.resample(\"W\").mean()\n",
    "                    df2=df2.dropna()\n",
    "                    df2[\"ds\"]=df2.index.tolist()\n",
    "                    tss = TimeSeriesSplit(n_splits = 5)\n",
    "                    days = np.sort(df2.index.unique())\n",
    "                    for train_index, test_index in tss.split(df2):\n",
    "                        train_days, test_days = days[train_index], days[test_index]\n",
    "                        X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            p[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                if i==\"exponential3\":\n",
    "                    es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "                    df2[\"y\"]=es_simple.fittedvalues\n",
    "                    tss = TimeSeriesSplit(n_splits = 5)\n",
    "                    days = np.sort(df2.index.unique())\n",
    "                    for train_index, test_index in tss.split(df2):\n",
    "                        train_days, test_days = days[train_index], days[test_index]\n",
    "                        X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in grid_prophet:\n",
    "                            print(i,j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in grid_neuralprophet:\n",
    "                            print(i,j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            p[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':i,'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "\n",
    "        minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"mape\"].argmin()])\n",
    "        self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd \n",
    "from sqlite3 import connect\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "from scipy.signal import detrend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "sns.set()\n",
    "import pandasql as psql\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def resample(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.resample(\"W\").mean()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def minmape(self):\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "            return self.minmape\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def resample(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.resample(\"W\").mean()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def resample(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.resample(\"W\").mean()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data):\n",
    "        from pytorch_lightning.callbacks import EarlyStopping\n",
    "        checkpoint_callback = EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters'])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\"},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\"},daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data):\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Taxformsmodels/Taxformsmodel\"+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Taxformsmodels/Taxformsmodel\"+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Taxformsmodels/Taxformsmodel\"+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Taxformsmodels/Taxformsmodel\"+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Taxformsmodels/Taxformsmodel\"+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Taxformsmodels/Taxformsmodel\"+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Taxformsmodels/Taxformsmodel\"+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Taxformsmodels/Taxformsmodel\"+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formnanme=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formnanme=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)],\"auto_lr_find\":True},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error,accuracy_score\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formnanme=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[4,8,12,16,32,128],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)],\"auto_lr_find\":True},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import accuracy_score,accuracy_score\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formnanme=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[4,8,12,16,32,128],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=accuracy_score(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=accuracy_score(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)],\"auto_lr_find\":True},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=accuracy_score(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=accuracy_score(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=accuracy_score(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=accuracy_score(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=accuracy_score(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=accuracy_score(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=accuracy_score(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=accuracy_score(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=accuracy_score(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=accuracy_score(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formnanme=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.05,0.1,0.5,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[4,8,16,32,128],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formnanme=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formnanme=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,progress=\"plot\",validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,progress=\"plot\",validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True,progress=\"plot\",validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(model, open(name, 'wb'))\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,progress=\"plot\",validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formnanme+str(self.i)+\".pkl\"\n",
    "                            pickle.dump(m, open(name, 'wb'))\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formnanme=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"W-SUN\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=10)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.01,0.1,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.001,0.005,0.01,0.05,0.1,0.5,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(X_train, freq=\"D\",early_stopping=True,checkpointing=True,validation_df=X_test)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet,set_log_level\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.1,0.5,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p,n_changepoints=0)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p,n_changepoints=0)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p,n_changepoints=0)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"resample\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p,n_changepoints=0)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet,set_log_level\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.1,0.5,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p,changepoints=[\"01-01-2021\",\"01-01-2022\",\"01-01-2023\"])\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p,changepoints=[\"01-01-2021\",\"01-01-2022\",\"01-01-2023\"])\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p,changepoints=[\"01-01-2021\",\"01-01-2022\",\"01-01-2023\"])\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p,changepoints=[\"01-01-2021\",\"01-01-2022\",\"01-01-2023\"])\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet,set_log_level\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.1,0.5,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'n_changepoints':[0,1,3,5,8,10],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet,set_log_level\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[0.1,0.5,1],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'n_changepoints':[0,3,5,10],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet,set_log_level\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[1,1.5,2],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'n_changepoints':[0,5,10],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=1000,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet,set_log_level\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"classical\",\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[1,1.5,2],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'n_changepoints':[0,5,10],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=100,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=100,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=100,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=100,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet,set_log_level\n",
    "import itertools \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from  neuralprophet import set_random_seed\n",
    "import pickle\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "class model_trainer:\n",
    "    def __init__(self,data,formsname):\n",
    "        self.formname=formsname\n",
    "        self.i=0\n",
    "        self.data=data\n",
    "        self.method=[\"prophet\",\"NeuralProphet\"]\n",
    "        self.model_parameters = pd.DataFrame(columns = ['Smoothing','Method','MAPE','Parameters',\"Number\"])\n",
    "        params_grid_prophet = {\n",
    "            'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "            'seasonality_mode':['additive', 'multiplicative'],\n",
    "            'weekly_seasonality':(True,False)\n",
    "            }\n",
    "        self.grid_prophet= [dict(zip(params_grid_prophet.keys(), v)) for v in itertools.product(*params_grid_prophet.values())]\n",
    "        params_grid_neuralprophet = {\n",
    "            \"learning_rate\":[1,1.5,2],\n",
    "            'seasonality_mode':('multiplicative','additive'),\n",
    "            'batch_size':[8,16,32],\n",
    "            'n_changepoints':[0,3,5,9,10],\n",
    "            'weekly_seasonality':(True,False)}\n",
    "        self.grid_neuralprophet= [dict(zip(params_grid_neuralprophet.keys(), v)) for v in itertools.product(*params_grid_neuralprophet.values())]\n",
    "    def rolling(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7).mean()\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=100,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def rolling_gaussian(self):\n",
    "            df2=self.data.copy()\n",
    "            df2[\"y\"]=df2[\"y\"].rolling(window=7,win_type=\"gaussian\").mean(std=10)\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"rolling-gaussian\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=100,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"rolling-gaussian\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def Nosmooth(self):\n",
    "            df2=self.data.copy()\n",
    "            df2=df2.dropna()\n",
    "            df2[\"ds\"]=df2.index.tolist()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=52,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"resample\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=100,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"Nosmooth\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "    def exponential3(self):\n",
    "            df2=self.data.copy()\n",
    "            es_simple = ExponentialSmoothing(df2[\"y\"], trend= 'add', damped= True, seasonal= 'add', seasonal_periods= 365).fit()\n",
    "            df2[\"y\"]=es_simple.fittedvalues\n",
    "            df2=df2.dropna()\n",
    "            tss = TimeSeriesSplit(n_splits = 5)\n",
    "            days = np.sort(df2.index.unique())\n",
    "            for train_index, test_index in tss.split(df2):\n",
    "                train_days, test_days = days[train_index], days[test_index]\n",
    "                X_train, X_test = df2.loc[train_days,], df2.loc[test_days,]\n",
    "            for j in self.method:\n",
    "                    if j==\"classical\":\n",
    "                        decomposeresult2=seasonal_decompose(df2[\"y\"],period=365,model=\"add\")\n",
    "                        season = pd.DataFrame({\"obs\":decomposeresult2.observed,\"trend\":decomposeresult2.trend,\"seasonal\":decomposeresult2.seasonal})\n",
    "                        season.index=pd.to_datetime(season.index)\n",
    "                        season=season.fillna(0)\n",
    "                        season[\"diff\"]=season[\"obs\"].sub(season[\"trend\"],axis=0)\n",
    "                        mape1=mean_absolute_percentage_error(df2[\"y\"], (season.seasonal+season.trend))\n",
    "                        self.i+=1\n",
    "                        self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':\"No parameter\",\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"prophet\":\n",
    "                        for p in self.grid_prophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            model = Prophet(daily_seasonality=False,**p)\n",
    "                            model=model.fit(X_train)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(model, name)\n",
    "                            forecast = model.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(X_test[\"y\"], forecast[\"yhat\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':p,\"Number\":self.i},ignore_index=True)\n",
    "                    if j==\"NeuralProphet\":\n",
    "                        for p in self.grid_neuralprophet:\n",
    "                            print(\"exponential3\",j,p)\n",
    "                            set_random_seed(0)\n",
    "                            set_log_level(\"ERROR\")\n",
    "                            m = NeuralProphet(trainer_config={\"accelerator\":\"gpu\",\"callbacks\":[EarlyStopping(monitor=\"Loss_val\",mode=\"min\",patience=5)]},\n",
    "                                              accelerator=\"gpu\",daily_seasonality=False,epochs=100,**p)\n",
    "                            df_train, df_val = m.split_df(df=X_train, freq=\"D\", valid_p=0.1)\n",
    "                            m.add_country_holidays(country_name='US')\n",
    "                            df_model=m.fit(df_train, freq=\"D\",early_stopping=True,validation_df=df_val)\n",
    "                            self.i+=1\n",
    "                            name=\"/home/batuhan-saylam/Desktop/JotformProject/projects/Formmodels/\"+self.formname+str(self.i)+\".pt\"\n",
    "                            torch.save(m, name)\n",
    "                            k=p.copy()\n",
    "                            k[\"epoch\" ]=df_model.iloc[-1,4]\n",
    "                            forecast = m.predict(X_test)\n",
    "                            mape1=mean_absolute_percentage_error(forecast[\"y\"], forecast[\"yhat1\"])\n",
    "                            self.model_parameters = self.model_parameters.append({'Smoothing':\"exponential3\",'Method':j,'MAPE':mape1,'Parameters':k,\"Number\":self.i},ignore_index=True)\n",
    "            minmape=pd.DataFrame(self.model_parameters.loc[self.model_parameters[\"MAPE\"].argmin()])\n",
    "            self.minmape=minmape.T\n",
    "    def picking(self,filename):\n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.model_parameters, file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
